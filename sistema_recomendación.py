# -*- coding: utf-8 -*-
"""Sistema_Recomendación_Celia_Garcia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w3bgdiwSIj6qZgk3OLI8Hi8p9GGc9dQE

# Sistema de recomendación de películas: *filtrado colaborativo basado en items*

La finalidad del proyecto es diseñar un sistema de recomendación simple para una plataforma de streaming, de manera que mediante la introducción del ID del usuario el sistema sea capaz de recomendar 5 películas en función de sus preferencias anteriores.

El proyecto consta de las siguientes partes:

*   Carga de datos y análisis exploratorio
*   Construcción del sistema de recomendación y ejemplos de funcionamiento
*   Evaluación del rendimiento del sistema
*   Consideraciones finales

## 1. Carga de datos y análisis exploratorio
---
"""

# Importación de librerías necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics.pairwise import pairwise_distances
from sklearn.model_selection import train_test_split

# Carga de los datasets sobre películas y califaciones de usuarios
ratings = pd.read_csv('ratings.csv')
movies = pd.read_csv('movies.csv')

# Visualización preliminar del dataset "movies"
print(movies.head())
print(movies.shape)

# Visualización preliminar del dataset "ratings"
print(ratings.head())
print(ratings.shape)

# Búsqueda de valores faltantes
print(movies.isnull().sum())
print(ratings.isnull().sum())

# Búsqueda de instancias duplicadas
print(movies.duplicated().sum())
print(ratings.duplicated().sum())

# Conservamos las columnas "movieId" y "title" en "movies"
movies = movies[["movieId","title"]]

# Conservamos las columnas "userId", "movieId" y "rating" para el dataset "ratings"
ratings = ratings[["userId","movieId","rating"]]

# Redefinición de columnas
movies = movies.rename(columns={"movieId": "movie_id"})
ratings = ratings.rename(columns={"userId": "user_id", "movieId": "movie_id"})

movies.head()

ratings.head()

# Análisis mediante gráficos de correlaciones de interés

# Distribución de las calificaciones desde 0.5 a 5 estrellas (10 posibles calificaciones)
sns.countplot(data=ratings, x='rating')
plt.title('Distribución de las calificaciones')
plt.xlabel('Calificaciones')
plt.ylabel('Cantidad de películas')
plt.show()

# Calificaciones por película
ratings_per_movie = ratings.groupby('movie_id').size()
sns.histplot(ratings_per_movie, bins=30)
plt.title('Distribución de la cantidad de calificaciones por película')
plt.xlabel('Número de calificaciones')
plt.ylabel('Cantidad de películas')
plt.show()

"""- Observamos como la distribucion de las calificaciones está sesgada, pues existen películas muy populares con muchas calificaciones en comparación con el resto. Esto puede llevar a que estas películas concretas sean más recomendadas que otras, a pesar de tener una calificación elevada.

"""

# Calcular de cuántos usuarios disponemos
print(ratings['user_id'].nunique())
print(ratings['movie_id'].nunique())

"""- Tenemos un total de 100836 calificaciones para 9724 películas de la plataforma, por parte de 610 usuarios."""

# Analizamos la cantidad de califcaciones por usuario y ordenamos de forma descendente
ratings_per_user = (ratings.groupby('user_id')['movie_id'].count()).sort_values(ascending=False)
ratings_per_user

# Extraemos datos de interés mediante .describe()
ratings_per_user.describe()

# Analizamos la cantidad de calificaciones por película y ordenamos de forma descendente
ratings_per_movie = ratings.groupby('movie_id').size()
ratings_per_movie.sort_values(ascending=False)

# Aplicamos .describe() a las calificaciones por pelicula
ratings_per_movie.describe()

"""- Por un lado, podemos observar que un 50% de las películas que contiene nuestro dataset tienen únicamente 3 o menos calificaciones, lo que seguramente afectará negativamente a nuestro recomendador.
- Dado que es una cantidad muy elevada de películas, prescindiremos al menos de aquellas que sólo tengan 1 calificación (no sirven para hallar similaridad).
- Por otro lado, los usuarios como mínimo tienen 20 valoraciones, por lo que por ahora vamos a intentar no prescindir de más datos.

"""

# Seleccionamos aquellas peliculas válidas, con al menos 2 valoraciones y menos de 100 (disminuir la influencia de las películas populares)
valid_movies = ratings_per_movie[(ratings_per_movie >= 2) & (ratings_per_movie <= 100)].index
ratings = ratings[ratings['movie_id'].isin(valid_movies)]
ratings_per_movie = ratings.groupby('movie_id').size()
ratings_per_movie

# Utilizamos .merge() para quedarnos con un único dataset "data" que incluya los títulos de las películas
data = pd.merge(movies, ratings, on='movie_id')
data.shape

data.head()

"""## 2. Construcción del sistema de recomendación y ejemplos de funcionamiento
---
"""

# Creamos una pivot table (las columnas son los títulos de las películas y las filas los usuarios)

user_item_matrix = data.pivot_table(index='user_id', columns='title', values='rating')
# Rellenamos con 0 los valores NaN para evitar errores  (el sistema toma los 0 como película no calificada, no como puntuación baja)
user_item_matrix.fillna(0, inplace=True)
user_item_matrix

# Calculamos similitudes de items usando distancia de Pearson y creamos un df de similaridad a partir de las mismas
item_similarity = 1 - pairwise_distances(user_item_matrix.T, metric='correlation')
item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix.columns, columns=user_item_matrix.columns)

item_similarity_df

# Función de recomendación utilizando todo el conjunto de datos

def recommend_movies(user_id):
  # Establecemos una condición por si el usuario introducido no existe
    if user_id not in user_item_matrix.index:
        return "El usuario no existe en la base de datos."

    # Obtenemos las calificaciones del usuario y calculamos las puntuaciones de similitud
    user_ratings = user_item_matrix.loc[user_id]
    similar_scores = user_ratings.dot(item_similarity_df)

    # Calculamos los pesos totales y calculamos las puntuaciones finales evitando las divisiones entre cero
    sum_of_weights = np.abs(item_similarity_df).sum(axis=1)
    similar_scores = similar_scores / sum_of_weights.where(sum_of_weights != 0, 1)

    # Obtenemos las  5 mejores recomendaciones
    recommendations = similar_scores.sort_values(ascending=False).head(5)
    recommended_movie_names = recommendations.index

    return recommended_movie_names

# Diferentes ejemplos de uso de la función de recomendación

user_id = 129 # Por ejemplo, recomendar para el usuario con ID 129
print(f"Recomendaciones para el usuario {user_id}: {recommend_movies(user_id)}")

user_id = 5
print(f"Recomendaciones para el usuario {user_id}: {recommend_movies(user_id)}")

user_id = 300
print(f"Recomendaciones para el usuario {user_id}: {recommend_movies(user_id)}")

user_id = 1000
print(f"Recomendaciones para el usuario {user_id}: {recommend_movies(user_id)}")

"""## 3. Evaluación del rendimiento del sistema
---

Evaluamos el rendimiento del sistema utilizando las métricas **precisión** y **exhaustividad** en un conjunto de prueba procedente del dataset completo, comparando las recomendaciones generadas con las películas relevantes para cada usuario.


"""

# Dividimos en conjunto de entrenamiento y de test para raelizar correctamente la evaluación
train_data, test_data = train_test_split(data, test_size=0.2, random_state=63)

# Creamos 2 matrices de usuario-item para el conjunto de entrenamiento y para el de prueba
train_user_item_matrix = train_data.pivot_table(index='user_id', columns='title', values='rating')
train_user_item_matrix.fillna(0, inplace=True)
test_user_item_matrix = test_data.pivot_table(index='user_id', columns='title', values='rating')
test_user_item_matrix.fillna(0, inplace=True)

# Aseguramos de que las columnas en "train_user_item_matrix" y "test_user_item_matrix" sean las mismas
common_movies = train_user_item_matrix.columns.intersection(test_user_item_matrix.columns)
test_user_item_matrix = test_user_item_matrix[common_movies]

# Calculamos similitudes de items usando distancia de Pearson y creamos un df de similaridad a partir de las mismas
item_similarity_train = 1 - pairwise_distances(train_user_item_matrix.T, metric='correlation')
item_similarity_df_train = pd.DataFrame(item_similarity_train, index=train_user_item_matrix.columns, columns=train_user_item_matrix.columns)

# Función de recomendación utilizando el conjunto de entrenamiento (misma estructura que la anterior)
def recommend_movies_train(user_id):
    if user_id not in train_user_item_matrix.index:
        return "El usuario no existe en la base de datos."

    user_ratings = train_user_item_matrix.loc[user_id]
    similar_scores = user_ratings.dot(item_similarity_df_train)
    sum_of_weights = np.abs(item_similarity_df_train).sum(axis=1)
    similar_scores = similar_scores / sum_of_weights.where(sum_of_weights != 0, 1)

    recommendations = similar_scores.sort_values(ascending=False).head(5)
    recommended_movie_names = recommendations.index

    return recommended_movie_names

# Función de cálculo de precisión
def calculate_precision(test_user_item_matrix, recommend_movies_train, num_recommendations=5):
    total_recomendaciones_relevantes = 0
    total_recomendaciones = 0

    # Iteramos sobre cada usuario en la matriz de usuario-item de prueba
    for user_id in test_user_item_matrix.index:
        # Películas relevantes para el usuario en el conjunto de prueba
        peliculas_relevantes_usuario = test_user_item_matrix.loc[user_id].dropna().index.tolist()

        # Obtener recomendaciones para el usuario y contar las que coinciden con aqueñllas películas relevantes para el usuario
        recomendaciones_usuario = recommend_movies_train(user_id)
        recomendaciones_relevantes = [pelicula for pelicula in recomendaciones_usuario if pelicula in peliculas_relevantes_usuario]

        # Actualizar contadores
        total_recomendaciones_relevantes += len(recomendaciones_relevantes)
        total_recomendaciones += len(recomendaciones_usuario)

    # Calcular precisión
    precision = total_recomendaciones_relevantes / total_recomendaciones if total_recomendaciones > 0 else 0

    return precision

precision = calculate_precision(test_user_item_matrix, recommend_movies_train, num_recommendations=5)
print("Precisión:", round((precision), 3))

# Función de cálculo de recall/exhaustividad
def calculate_recall(test_user_item_matrix, recommend_movies_train):
    total_recomendaciones_relevantes = 0
    total_relevantes = 0

    # Iteramos sobre cada usuario en la matriz de usuario-item de prueba
    for user_id in test_user_item_matrix.index:
        # Películas relevantes para el usuario en el conjunto de prueba
        peliculas_relevantes_usuario = test_user_item_matrix.loc[user_id].dropna().index.tolist()

        # Obtener recomendaciones para el usuario
        recomendaciones_usuario = recommend_movies_train(user_id)

        # Contar recomendaciones relevantes
        recomendaciones_relevantes = [pelicula for pelicula in recomendaciones_usuario if pelicula in peliculas_relevantes_usuario]

        # Actualizar contadores
        total_recomendaciones_relevantes += len(recomendaciones_relevantes)
        total_relevantes += len(peliculas_relevantes_usuario)

    # Calcular exhaustividad (recall) (manejo de división por cero)
    exhaustividad = total_recomendaciones_relevantes / total_relevantes if total_relevantes > 0 else 0

    return exhaustividad

exhaustividad = calculate_recall(test_user_item_matrix, recommend_movies_train)
print("Exhaustividad:", exhaustividad)

"""## 4. Consideraciones finales
---

- El sistema de recomendación desarrollado muestra un buen desempeño en términos de precisión, pero necesita mejorar en términos de exhaustividad o recall.
- Se ha intentado mejorar la calidad de los datos reduciendo la cantidad de películas con poca valoraciones, reduciendo las calificaciones de aquellas películas más populares, entre otras decisiones. No obstante, parece que son otros factores los que están afectando al sistema de recomendación.


- **Posibles mejoras:**
1. Ampliar el conjunto de datos (posiblemente con más de 100000 ratings mejoraría la diversidad de las recomendaciones).

2. Utilizar otros algoritmos de filtrado colaborativo algo más complejo que el de "por items" que permitan más información para recomendar (por ejemplo, utilizar filtrado colaborativo "por contenido").
"""